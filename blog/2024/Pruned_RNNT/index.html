<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Pruned RNN-T Explained | Sangeet Sagar</title> <meta name="author" content="Sangeet Sagar"> <meta name="description" content="This blog explains the paper- ``Pruned RNN-T for fast, memory-efficient ASR training''"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%92%AC&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://sangeet2020.github.io/blog/2024/Pruned_RNNT/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "Pruned RNN-T Explained",
      "description": "This blog explains the paper- ``Pruned RNN-T for fast, memory-efficient ASR training''",
      "published": "January 7, 2024",
      "authors": [
        {
          "author": "Sangeet Sagar",
          "authorURL": "",
          "affiliations": [
            {
              "name": "EML Speech Technology GmbH",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Sangeet </span>Sagar</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/ms-thesis/">MS Thesis</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/bc-thesis/">BC Thesis</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Pruned RNN-T Explained</h1> <p>This blog explains the paper- ``Pruned RNN-T for fast, memory-efficient ASR training''</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#paper-theme">Paper theme</a></div> <div><a href="#introduction">Introduction</a></div> <div><a href="#motivations">Motivations</a></div> <div><a href="#pruned-rnn-t">Pruned RNN-T</a></div> <div><a href="#experimental-settings">Experimental Settings</a></div> </nav> </d-contents> <h2 id="paper-theme"><strong>Paper theme</strong></h2> <p>RNN-T has a slow and memory-intensive loss function, limiting its use for large vocabularies like Chinese characters. The main idea of Pruned RNN-T is to reduce computational and memory requirements by selectively evaluating the joiner network, leading to faster training and maintained accuracy. Pruning bounds are obtained using a linear joiner network in the encoder and decoder embeddings.</p> <p><a href="https://github.com/k2-fsa/k2/blob/415fe1f446fffe1d9e7219b5033966294c0b430c/k2/python/k2/rnnt_loss.py#L636" rel="external nofollow noopener" target="_blank">Source Code</a></p> <h2 id="introduction"><strong>Introduction</strong></h2> <ul> <li> <p>Three popular E2E models are CTC models, attention-based models, and RNN-T models, with RNN-T being suitable for streaming decoding and doesn’t assume frames are independent,</p> </li> <li>The output of an RNN-T model is a 4-D tensor (\(N\), \(T\), \(U\), \(V\)) <ul> <li>\(N\) : batch size</li> <li>\(T\) : output length</li> <li>\(U\) : prediction length</li> <li>\(V\) : vocabulary size, which consumes a lot of memory.</li> </ul> </li> <li>Removing padding, function merging and half-precision training are approaches to reduce memory usage in RNN-T</li> <li>In this paper RNN-T = RNN-T loss = transducer loss</li> <li>The paper uses a Conformer encoder and a stateless decoder in their experiments, not a recurrent encoder and decoder.</li> </ul> <h2 id="motivations"><strong>Motivations</strong></h2> <div class="row justify-content-center"> <div class="col-sm mt-3 mt-md-0" style="max-width: 300px; text-align: center;"> <figure> <picture> <img src="/assets/img/transducer_model.png" class="img-fluid rounded z-depth-1 mx-auto" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Illustration of a generic transducer model. <a href="https://lorenlugosch.github.io/posts/2020/11/transducer/" rel="external nofollow noopener" target="_blank">Reference</a> (Lugosch, 2020) </div> <p><strong>Tokens:</strong></p> <ul> <li>The transducer model utilizes tokens, such as the Beginning-Of-Sequence (BOS) token <code class="language-plaintext highlighter-rouge">&lt;s&gt;</code> placed at <code class="language-plaintext highlighter-rouge">y0</code>, and a blank token (∅). It has no EOS.</li> </ul> <p><strong>Equations:</strong></p> <ul> <li> <strong>Input Features:</strong> <ul> <li>Denoted as: \(\mathbf{x} = \{x_0, x_1, x_2, \ldots, x_{t-1}\} \equiv X_{(T, E)}\)</li> <li>These represent the input features, typically derived from audio or text data.</li> </ul> </li> <li> <strong>Tokenized Transcript:</strong> <ul> <li>Denoted as: \(\mathbf{y} = \{y_0, y_1, y_2, \ldots, y_u\}\) (with a total of \(U\) tokens)</li> <li>Represents the tokenized transcript, where each \(y_i\) corresponds to a token in the output sequence.</li> </ul> </li> <li> <strong>Predictor Network (Decoder):</strong> <ul> <li>The predictor network, or decoder, is autoregressive. It takes the previous output as input and generates features used for generating the next output token.</li> </ul> </li> <li>RNN-T loss computation can be memory and compute-intensive due to the large output shape: \(N \times T \times U \times V\).</li> </ul> <div class="row justify-content-center"> <div class="col-sm mt-3 mt-md-0" style="max-width: 600px; text-align: center;"> <figure> <picture> <img src="/assets/img/Pruned_RNNT_lattice.png" class="img-fluid rounded z-depth-1 mx-auto" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This illustration shows the lattice in standard RNN-T (right) vs pruned RNN-T (left). <a href="https://arxiv.org/pdf/2206.13236.pdf" rel="external nofollow noopener" target="_blank">arXiv</a> (Fangjun Kuang, 2022) </div> <details><summary>What is a lattice? and why is it important?</summary> <p>The lattice represents the log-probs of transition between the time steps and label indices. They are important because they capture the likelihood of transition to a token at a time step.</p> </details> <ul> <li>Pruned RNN-T limits the token range from \(U\) to \(S\) at each time step, reducing output shape to \((T, S, V)\). This reduction reduces memory consumption and speeds up training.</li> </ul> <h2 id="pruned-rnn-t"><strong>Pruned RNN-T</strong></h2> <ul> <li>Pruned RNN-T selectively evaluates the joiner network for specific $(t, u)$ pairs that have a significant impact on the final loss. This is achieved by performing the core recursion of the model twice: <ul> <li>First, with a “trivial” joiner network, which is fast to evaluate, to identify important pairs.</li> <li>Then, the full joiner network is evaluated only for a subset of (t, u) pairs.</li> </ul> </li> <li> <p><strong>Trivial joiner network</strong>: The trivial joiner network is a simplified approach to computing the joiner network in the RNN-T model, using matrix multiplication and lookups to efficiently obtain log probabilities for the pruned RNN-T model. \(y(t,u) \rightarrow \text{log-probs of vertical transition}\)<br> \(\phi(t,u) \rightarrow \text{log-probs of horizontal transition}\)<br> \(L_{enc}(t,u) \rightarrow \text{unnormalized log-probs associated with encoder}\)<br> \(L_{dec}(t,u) \rightarrow \text{unnormalized log-probs associated with decoder aka. prediction network}\)<br></p> <p>Log probs associated with the joiner is given by</p> \[L_{trivial} = L_{enc} + L_{dec} - \log \left( \sum \exp({L_{enc} + L_{dec}}) \right)\] <p>this equation allows us to compute \(y(t,u)\) and \(\phi(t,u)\)</p> </li> <li> <strong>Pruning bounds</strong>: Pruning involves selecting a constant \(S\) (eg 4 or 5) to limit the evaluation of \(L(t, u, v)\) for specific \(u\) indexes within a given \(t\) index. In the above illustration, the lattice on the right will have \(L(t,u,v)\) computed for only for \(p_t \leq u &lt; p_t + S\) indices, while the rest is set to \(-\infty\). To compute the <strong>globally optimal pruning bounds</strong> we want to find a sequence of integer pruning bounds \(p=p_0, p_t, ... p_{T-1}\) that maximizes the total retained probability. It is basically finding positions for pruning in the lattice such that the total probability of retained transition is maximized. Here we are trying to retain the highest probability transition while discarding the less relevant ones.</li> </ul> <p>In the context of the pruned RNN-T model, the quantities \(y′(t, u)\) and \(\phi′(t, u)\) represent “occupation counts” within a specific interval, indicating the likelihood of upward and rightward transitions. Lets estimate the retained probability mass for \(S=4\) (no. of label indices to be evaluated at each time step \(t\)) and \(p_t=2\) (pruning bound)–</p> \[\phi'(t,2) + \phi'(t,3) + \phi'(t,4) + \phi'(t,5) - y'(t,1)\] <p>The occupation count \(y'\) in the above equation represents the probability associated with label index 1 which is red in the above lattice diagram. The subtraction is done to make the calculation more accurate by compensating for the inclusion of some probability mass that should have been pruned out due to lower \(u\) values.</p> <ul> <li> <strong>Loss function</strong>: <a href="https://github.com/k2-fsa/k2/blob/415fe1f446fffe1d9e7219b5033966294c0b430c/k2/python/k2/rnnt_loss.py#L450" rel="external nofollow noopener" target="_blank">Source Code</a> The loss function is a combination of log-probs from trivial joiner network and full joiner network.</li> </ul> \[L_{smoothed} = (1- \alpha^{lm} - \alpha^{acoustic})L_{trivial} + \alpha^{lm}L_{lm} + \alpha^{acoustic}L_{lm}\] <p><em>Refer to Section 3.3 in the paper for a more detailed explanation</em></p> <h2 id="experimental-settings"><strong>Experimental Settings</strong></h2> <table border="1" cellpadding="5"> <tr> <th>Category</th> <th>Parameter/Hyperparameter</th> <th>Value</th> </tr> <tr> <td rowspan="4">Dataset</td> <td>Corpus</td> <td>LibriSpeech</td> </tr> <tr> <td>Training Hours</td> <td>960 hours</td> </tr> <tr> <td>Test Sets</td> <td>test-clean, test-other</td> </tr> <tr> <td>Test Set Speech Duration</td> <td>Approximately 5 hours each</td> </tr> <tr> <td rowspan="3">Input Features</td> <td>Feature Type</td> <td>80-dimension log Mel filter bank</td> </tr> <tr> <td>Window Size</td> <td>25 ms</td> </tr> <tr> <td>Window Shift</td> <td>10 ms</td> </tr> <tr> <td>Data Augmentation</td> <td>SpecAugment Factors</td> <td>0.9 and 1.1</td> </tr> <tr> <td rowspan="4">Model Architecture</td> <td>Encoder</td> <td>Conformer with 12 layers</td> </tr> <tr> <td>Encoder Self-Attention</td> <td>8 heads</td> </tr> <tr> <td>Encoder Attention Dim</td> <td>512</td> </tr> <tr> <td>Encoder Feed-Forward Dim</td> <td>2048</td> </tr> <tr> <td rowspan="2">Decoder</td> <td>Stateless decoder with embedding layer and 1-D convolutional layer</td> <td> </td> </tr> <tr> <td>Decoder Embedding Dim</td> <td>512</td> </tr> <tr> <td>GPUs</td> <td>Number of GPUs</td> <td>8 NVIDIA V100 32GB GPUs</td> </tr> <tr> <td rowspan="2">Training Strategy</td> <td>Pruning Strategy</td> <td>Enable pruned loss after convergence of trivial loss</td> </tr> </table> <h2 id="results">Results</h2> <ul> <li>Pruned RNN-T outperforms other implementations in terms of speed and memory efficiency.</li> <li>When comparing Word Error Rates (WERs) on the LibriSpeech test-clean and test-other datasets, the model trained with pruned RNN-T shows slightly better WER performance compared to the model trained with unpruned RNN-T loss. This suggests that pruned RNN-T can achieve comparable or better accuracy in ASR tasks.</li> </ul> <div class="row justify-content-center"> <div class="col-sm mt-3 mt-md-0" style="max-width: 500px; text-align: center;"> <figure> <picture> <img src="/assets/img/Pruned_RNNT_results.png" class="img-fluid rounded z-depth-1 mx-auto" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>The memory efficiency of pruned RNN-T allows for the use of larger batch sizes and vocabulary sizes during training, which further contributes to its speed advantage.</li> </ul> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Sangeet Sagar. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>